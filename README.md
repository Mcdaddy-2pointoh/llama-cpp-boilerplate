# llama-cpp-boilerplate
 A boilerplate codeblock to spin up GGUF based llm models on cpu instances and serve it using fast api servers
